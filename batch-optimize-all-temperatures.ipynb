{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Batch Optimization for All Temperatures (Parametric Curve Fitting)\n\n**Runs the parametric curve-fitting optimization pipeline for all temperature datasets.**\n\n## Curve-Fitting Approach\n\nWe fit the parametric curve V(L) where both V and L are computed from parameters a, b:\n- L(z) = (2/π) ∫ sqrt(g(z'))/sqrt((z⁴f(z))/(z'⁴f(z')) - 1) dz'\n- V(z) = 2π ∫ [1/z'² (sqrt(fg)/sqrt(1 - z'⁴f(z)/(z⁴f(z'))) - 1)] dz' - 2π/z\n\n## Loss Function\n\n```\nLoss = DataFitError + λ·NECPenalty\n```\n\nwhere:\n- DataFitError = Mean[(V_model - V_data)²]\n- NECPenalty = Max[0, Max_z[Σ(n+1)(aₙ+bₙ)zⁿ]]²\n- λ = 100 (tunable weight)\n\n**Outputs for each temperature:**\n- `results/T{temp}_params.txt` - Optimized parameters\n- `results/T{temp}_fit.png` - Plot of data vs optimized model\n- `results/T{temp}_convergence.png` - Convergence plots for a, b, objective\n- `results/all_temperatures_summary.txt` - Summary table of all results"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import differential_evolution, Bounds\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from dataset_HR import AdSBHDataset\n",
    "from model_HR_new import AdSBHNet\n",
    "from constants import dreal, dcomplex\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved to: /Users/helitakko/Dropbox/Own/deep-learning-EE/env-mac/complex_wilson/results\n"
     ]
    }
   ],
   "source": [
    "# Create results directory\n",
    "results_dir = Path('results')\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "print(f\"Results will be saved to: {results_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find All Temperature Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 temperature datasets (1607 series only):\n",
      "  T = 113 MeV: 1607latticeT113.txt\n",
      "  T = 226 MeV: 1607latticeT226.txt\n",
      "  T = 254 MeV: 1607latticeT254.txt\n",
      "  T = 271 MeV: 1607latticeT271.txt\n",
      "  T = 290 MeV: 1607latticeT290.txt\n",
      "  T = 312 MeV: 1607latticeT312.txt\n",
      "  T = 338 MeV: 1607latticeT338.txt\n",
      "  T = 369 MeV: 1607latticeT369.txt\n",
      "  T = 406 MeV: 1607latticeT406.txt\n"
     ]
    }
   ],
   "source": [
    "# Find all lattice data files (only 1607 series)\n",
    "files = sorted(glob.glob('1607latticeT*.txt'))\n",
    "\n",
    "# Extract temperature from filename\n",
    "temp_files = []\n",
    "for f in files:\n",
    "    match = re.search(r'T(\\d+)', f)\n",
    "    if match:\n",
    "        temp = int(match.group(1))\n",
    "        temp_files.append((temp, f))\n",
    "\n",
    "temp_files.sort()\n",
    "\n",
    "print(f\"Found {len(temp_files)} temperature datasets (1607 series only):\")\n",
    "for temp, f in temp_files:\n",
    "    print(f\"  T = {temp:3d} MeV: {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Optimization Pipeline (Same as Single-Temperature Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COEFFS = 4\n",
    "\n",
    "@torch.no_grad()\n",
    "def connected_branch(model, device, dt, zmin=0.02, zmax=0.9995, Nc=3000):\n",
    "    zs = torch.linspace(zmin, zmax, Nc, dtype=dt, device=device)\n",
    "    Lc = model.integrate_L(zs).real\n",
    "    Vc = model.integrate_V(zs).real\n",
    "    idx = torch.argsort(Lc)\n",
    "    Lc, Vc = Lc[idx], Vc[idx]\n",
    "    imax = torch.argmax(Lc)\n",
    "    return Lc[:imax+1], Vc[:imax+1]\n",
    "\n",
    "@torch.no_grad()\n",
    "def interp_1d(x, y, xq, eps=1e-12):\n",
    "    if x.numel() < 2:\n",
    "        return torch.full_like(xq, y[0] if y.numel() > 0 else 0.0)\n",
    "    xq = torch.as_tensor(xq, dtype=x.dtype, device=x.device).reshape(-1)\n",
    "    pos = torch.searchsorted(x, xq, right=True)\n",
    "    i0 = (pos - 1).clamp(0, x.numel() - 2)\n",
    "    i1 = i0 + 1\n",
    "    x0, x1, y0, y1 = x[i0], x[i1], y[i0], y[i1]\n",
    "    w = (xq - x0) / (x1 - x0 + eps)\n",
    "    v_lin = y0 + w * (y1 - y0)\n",
    "    mL = (y[1] - y[0]) / (x[1] - x[0] + eps)\n",
    "    mR = (y[-1] - y[-2]) / (x[-1] - x[-2] + eps)\n",
    "    v_left = y[0] + mL * (xq - x[0])\n",
    "    v_right = y[-1] + mR * (xq - x[-1])\n",
    "    v = torch.where(xq < x[0], v_left, v_lin)\n",
    "    v = torch.where(xq > x[-1], v_right, v)\n",
    "    return v\n",
    "\n",
    "@torch.no_grad()\n",
    "def pack_params(model):\n",
    "    a_np = model.a.detach().cpu().numpy().astype(np.float64)\n",
    "    b_np = model.b.detach().cpu().numpy().astype(np.float64)\n",
    "    N = len(a_np)\n",
    "    return np.concatenate([a_np[0:1], a_np[1:], b_np[1:]])\n",
    "\n",
    "@torch.no_grad()\n",
    "def unpack_params(model, theta, device, dt):\n",
    "    theta = np.asarray(theta, dtype=np.float64)\n",
    "    N = model.a.numel()\n",
    "    a0 = theta[0]\n",
    "    a_rest = theta[1:N]\n",
    "    b_rest = theta[N:2*N-1]\n",
    "    b0 = -a0\n",
    "    a_np = np.concatenate([[a0], a_rest])\n",
    "    b_np = np.concatenate([[b0], b_rest])\n",
    "    model.a.copy_(torch.tensor(a_np, dtype=dt, device=device))\n",
    "    model.b.copy_(torch.tensor(b_np, dtype=dt, device=device))\n",
    "\n",
    "def get_bounds(N):\n",
    "    lower = np.concatenate([[-0.5], [-0.1]*(N-1), [0.05]*(N-1)])\n",
    "    upper = np.concatenate([[-0.05], [0.6]*(N-1), [0.3]*(N-1)])\n",
    "    return Bounds(lower, upper)\n",
    "\n",
    "@torch.no_grad()\n",
    "def nec_penalty(a, b, device, dt, num_samples=100):\n",
    "    \"\"\"\n",
    "    Compute NEC (Null Energy Condition) violation penalty.\n",
    "    \n",
    "    NEC requires: -(3/2z) * [a'(z) + b'(z)] >= 0 for all z in [0, 1]\n",
    "    This means: (a0+b0) + 2(a1+b1)z + 3(a2+b2)z^2 + 4(a3+b3)z^3 <= 0\n",
    "    \n",
    "    We penalize violations where P(z) > 0.\n",
    "    \"\"\"\n",
    "    z = torch.linspace(0.01, 0.99, num_samples, dtype=dt, device=device)\n",
    "    \n",
    "    # Compute polynomial P(z) = sum (n+1)(an+bn)z^n\n",
    "    P = (a[0] + b[0]) + 2*(a[1] + b[1])*z + 3*(a[2] + b[2])*z**2 + 4*(a[3] + b[3])*z**3\n",
    "    \n",
    "    # NEC violation if P > 0\n",
    "    violation = torch.relu(P).max()\n",
    "    \n",
    "    return float(violation.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def optimize_params_all_temperatures(filename, temp, verbose=True):\n    \"\"\"\n    Run parametric curve-fitting optimization for a single temperature.\n    \n    Uses the new loss formulation:\n        Loss = DataFitError + λ·NECPenalty\n    \n    Returns:\n        dict with keys: a, b, coef, shift, obj_final, Lmax_model, success\n    \"\"\"\n    if verbose:\n        print(f\"\\n{'='*70}\")\n        print(f\"OPTIMIZING T = {temp} MeV\")\n        print(f\"File: {filename}\")\n        print(f\"{'='*70}\")\n    \n    # Load data\n    dataset = AdSBHDataset(file=filename)\n    mask_L = dataset.L < 1.4\n    L_all = dataset.L[mask_L]\n    V_all = dataset.V[mask_L]\n    sigma_all = dataset.sigma[mask_L]\n    \n    if verbose:\n        print(f\"  Dataset: {len(L_all)} points\")\n        print(f\"  L range: [{L_all.min():.4f}, {L_all.max():.4f}]\")\n    \n    # Setup model\n    model = AdSBHNet(N=N_COEFFS, std=0.1)\n    device = model.a.device\n    dt = model.a.dtype\n    \n    L_all = L_all.to(device=device, dtype=dt)\n    V_all = V_all.to(device=device)\n    sigma_all = sigma_all.to(device=device)\n    \n    # Initialize model\n    model.a.zero_()\n    model.b.zero_()\n    model.a[0] = -0.25\n    model.b[0] = 0.25\n    \n    if model.a.numel() > 1:\n        model.a[1:] = torch.tensor([0.26, 0.31, 0.33], dtype=dt, device=device)\n        model.b[1:] = torch.tensor([0.12, 0.12, 0.13], dtype=dt, device=device)\n    \n    # LS initialization for coef and shift\n    Lm, Vm = connected_branch(model, device, dt)\n    if Lm.numel() >= 2:\n        mask = (L_all >= Lm[0]) & (L_all <= Lm[-1])\n        if mask.sum() >= 3:\n            L_fit = L_all[mask]\n            V_fit = V_all.real[mask]\n            X_fit = interp_1d(Lm, Vm, L_fit)\n            X_np = X_fit.cpu().numpy().reshape(-1, 1)\n            Y_np = V_fit.cpu().numpy()\n            reg = LinearRegression().fit(X_np, Y_np)\n            coef = max(float(reg.coef_[0]), 1e-6)\n            shift = float(reg.intercept_)\n            model.logcoef.copy_(torch.tensor(np.log(coef), dtype=dt, device=device))\n            model.shift.copy_(torch.tensor(shift, dtype=dt, device=device))\n    \n    if verbose:\n        print(f\"  LS init: coef={np.exp(float(model.logcoef.detach())):.6f}, shift={float(model.shift.detach()):.6f}\")\n        print(f\"  Initial swallowtail at L_max = {Lm[-1].item():.4f}\")\n    \n    theta0 = pack_params(model)\n    bounds = get_bounds(N_COEFFS)\n    \n    # Define objective with new loss formulation\n    iteration_counter = [0]\n    a_history = []\n    b_history = []\n    obj_history = []\n    \n    @torch.no_grad()\n    def objective(theta, return_components=False):\n        \"\"\"\n        Loss = DataFitError + λ·NECPenalty\n        \n        where:\n          DataFitError = Mean[(V_model - V_data)²]\n          NECPenalty = Max[0, Max_z[Σ(n+1)(aₙ+bₙ)zⁿ]]²\n        \"\"\"\n        unpack_params(model, theta, device, dt)\n        iteration_counter[0] += 1\n        a_history.append(model.a.detach().cpu().numpy().copy())\n        b_history.append(model.b.detach().cpu().numpy().copy())\n        \n        try:\n            Lm, Vm = connected_branch(model, device, dt)\n        except:\n            obj_history.append(1e10)\n            return 1e10 if not return_components else (1e10, {})\n        \n        if Lm.numel() < 5 or not torch.isfinite(Lm).all() or not torch.isfinite(Vm).all():\n            obj_history.append(1e10)\n            return 1e10 if not return_components else (1e10, {})\n        \n        # Interpolate V_model at data points L\n        V_model = interp_1d(Lm, Vm, L_all) + model.shift\n        residuals = V_model - V_all.real\n        \n        # Data fit error: Mean[(V_model - V_data)²]\n        w_stat = 1.0 / (sigma_all.real**2 + 1e-12)\n        L_weight = (L_all / L_all.max()).clamp_min(0).pow(2.0)\n        w_total = w_stat * L_weight\n        \n        data_fit_error = float((w_total * residuals**2).mean().item())\n        \n        # NEC penalty: Max[0, Max_z[P(z)]]²\n        z_samples = torch.linspace(0.01, 0.99, 100, dtype=dt, device=device)\n        P = ((model.a[0] + model.b[0]) + \n             2*(model.a[1] + model.b[1])*z_samples + \n             3*(model.a[2] + model.b[2])*z_samples**2 + \n             4*(model.a[3] + model.b[3])*z_samples**3)\n        \n        nec_violation = torch.relu(P).max()\n        nec_penalty_term = float((nec_violation ** 2).item())\n        \n        # Weight parameter λ for NEC penalty\n        lambda_nec = 100.0\n        \n        # Total loss\n        total_loss = data_fit_error + lambda_nec * nec_penalty_term\n        \n        # Additional soft constraints\n        Lmax_model = float(Lm[-1].item())\n        swallowtail_penalty = 0.0\n        target_L_min, target_L_max = 0.35, 0.60\n        \n        if Lmax_model < target_L_min:\n            swallowtail_penalty = 10.0 * ((target_L_min - Lmax_model) / target_L_min) ** 2\n        elif Lmax_model > target_L_max:\n            swallowtail_penalty = 10.0 * ((Lmax_model - target_L_max) / target_L_max) ** 2\n        \n        Lmax_data = float(L_all.max().item())\n        coverage_penalty = 0.0\n        if Lmax_model < Lmax_data:\n            gap = (Lmax_data - Lmax_model) / max(Lmax_data, 1e-6)\n            coverage_penalty = 5.0 * (gap**2)\n        \n        reg_L2 = 1e-5 * float((model.a**2).sum().item() + (model.b**2).sum().item())\n        \n        # Total objective\n        total = total_loss + swallowtail_penalty + coverage_penalty + reg_L2\n        obj_history.append(total)\n        \n        if return_components:\n            return total, {\n                'data_fit_error': data_fit_error,\n                'nec_penalty': nec_penalty_term,\n                'nec_violation': float(nec_violation.item()),\n                'total_loss': total_loss,\n                'swallowtail_penalty': swallowtail_penalty,\n                'coverage_penalty': coverage_penalty,\n                'reg_L2': reg_L2,\n                'Lmax_model': Lmax_model,\n                'Lmax_data': Lmax_data,\n                'chi2_data': data_fit_error  # For backward compatibility\n            }\n        return total\n    \n    # Run optimization\n    if verbose:\n        print(f\"  Running differential evolution...\")\n        print(f\"  Loss = DataFitError + λ·NECPenalty (λ=100)\")\n    \n    result = differential_evolution(\n        objective,\n        bounds=[(bounds.lb[i], bounds.ub[i]) for i in range(len(bounds.lb))],\n        maxiter=50,\n        popsize=10,\n        strategy='best1bin',\n        atol=1e-6,\n        tol=1e-6,\n        mutation=(0.5, 1.5),\n        recombination=0.7,\n        seed=42,\n        polish=True,\n        workers=1,\n        disp=False\n    )\n    \n    unpack_params(model, result.x, device, dt)\n    obj_final, comp_final = objective(result.x, return_components=True)\n    \n    if verbose:\n        print(f\"  Optimization complete!\")\n        print(f\"    Success: {result.success}\")\n        print(f\"    Final loss: {comp_final['total_loss']:.4e}\")\n        print(f\"      DataFitError: {comp_final['data_fit_error']:.4e}\")\n        print(f\"      NECPenalty: {comp_final['nec_penalty']:.4e}\")\n        print(f\"      NEC violation: {comp_final['nec_violation']:.4e}\")\n        print(f\"    Swallowtail at L_max = {comp_final['Lmax_model']:.4f}\")\n        print(f\"    Function evaluations: {result.nfev}\")\n    \n    # Extract final parameters\n    a_final = model.a.detach().cpu().numpy()\n    b_final = model.b.detach().cpu().numpy()\n    coef_final = np.exp(float(model.logcoef.detach()))\n    shift_final = float(model.shift.detach())\n    \n    # Generate plots\n    if verbose:\n        print(f\"  Generating plots...\")\n    \n    # Plot 1: Fit\n    fig, ax = plt.subplots(figsize=(8, 6))\n    with torch.no_grad():\n        Lm_final, Vm_final = connected_branch(model, device, dt, Nc=5000)\n        V_branch = Vm_final + model.shift\n    \n    ax.plot(Lm_final.cpu(), V_branch.cpu(), 'r-', linewidth=2.5,\n            label='Optimized', alpha=0.8, zorder=2)\n    ax.errorbar(L_all.cpu(), V_all.real.cpu(), yerr=sigma_all.real.cpu(),\n                fmt='o', markersize=6, alpha=0.7, label='Data', color='blue', zorder=1)\n    ax.set_xlabel(r'$T L$', fontsize=13)\n    ax.set_ylabel(r'$V/T$', fontsize=13)\n    ax.set_title(f'T = {temp} MeV: Data vs Optimized Model', fontsize=14)\n    ax.legend(fontsize=11)\n    ax.grid(alpha=0.3)\n    plt.tight_layout()\n    plt.savefig(results_dir / f'T{temp}_fit.png', dpi=150, bbox_inches='tight')\n    plt.close()\n    \n    # Plot 2: Convergence\n    a_hist_np = np.array(a_history)\n    b_hist_np = np.array(b_history)\n    iterations = np.arange(1, len(a_history) + 1)\n    \n    n_a = a_hist_np.shape[1]\n    n_b = b_hist_np.shape[1]\n    \n    warm = plt.cm.OrRd(np.linspace(0.9, 0.45, n_a))\n    cold = plt.cm.Blues(np.linspace(0.9, 0.45, n_b))\n    \n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    \n    # Coefficients\n    ax = axes[0]\n    for i in range(n_a):\n        ax.plot(iterations, a_hist_np[:, i], color=warm[i], label=f'a[{i}]', linewidth=2)\n    for i in range(n_b):\n        ax.plot(iterations, b_hist_np[:, i], color=cold[i], linestyle='--', label=f'b[{i}]', linewidth=2)\n    ax.set_xlabel('Iteration', fontsize=12)\n    ax.set_ylabel('Coefficient Value', fontsize=12)\n    ax.set_title(f'T = {temp} MeV: Coefficient Convergence', fontsize=13)\n    ax.legend(ncol=2, fontsize=10)\n    ax.grid(alpha=0.3)\n    \n    # Objective\n    ax = axes[1]\n    ax.plot(iterations, obj_history, 'k-', linewidth=2, alpha=0.7)\n    ax.set_xlabel('Iteration', fontsize=12)\n    ax.set_ylabel('Loss Value', fontsize=12)\n    ax.set_title(f'T = {temp} MeV: Loss Convergence', fontsize=13)\n    ax.set_yscale('log')\n    ax.grid(alpha=0.3, which='both')\n    \n    plt.tight_layout()\n    plt.savefig(results_dir / f'T{temp}_convergence.png', dpi=150, bbox_inches='tight')\n    plt.close()\n    \n    # Save parameters to text file\n    with open(results_dir / f'T{temp}_params.txt', 'w') as f:\n        f.write(f\"Temperature: {temp} MeV\\n\")\n        f.write(f\"File: {filename}\\n\")\n        f.write(f\"\\n{'='*60}\\n\")\n        f.write(f\"PARAMETRIC CURVE FITTING RESULTS\\n\")\n        f.write(f\"{'='*60}\\n\\n\")\n        \n        f.write(\"Loss = DataFitError + λ·NECPenalty\\n\")\n        f.write(f\"  DataFitError: {comp_final['data_fit_error']:.6e}\\n\")\n        f.write(f\"  NECPenalty: {comp_final['nec_penalty']:.6e}\\n\")\n        f.write(f\"  λ: 100.0\\n\")\n        f.write(f\"  Total Loss: {comp_final['total_loss']:.6e}\\n\\n\")\n        \n        f.write(\"Coefficients a:\\n\")\n        for i, val in enumerate(a_final):\n            f.write(f\"  a[{i}] = {val:.10f}\\n\")\n        \n        f.write(\"\\nCoefficients b:\\n\")\n        for i, val in enumerate(b_final):\n            f.write(f\"  b[{i}] = {val:.10f}\\n\")\n        \n        f.write(\"\\nScale and shift:\\n\")\n        f.write(f\"  coef = {coef_final:.10f}\\n\")\n        f.write(f\"  shift = {shift_final:.10f}\\n\")\n        \n        f.write(\"\\nLoss components:\\n\")\n        for k, v in comp_final.items():\n            f.write(f\"  {k}: {v:.6e}\\n\")\n        \n        f.write(\"\\nConstraints:\\n\")\n        f.write(f\"  a[0] + b[0] = {(a_final[0] + b_final[0]):.6e}\\n\")\n        f.write(f\"  a[0] < 0: {a_final[0] < 0}\\n\")\n        f.write(f\"  NEC satisfied: {comp_final['nec_violation'] < 1e-6}\\n\")\n        \n        f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n        f.write(\"Python format:\\n\")\n        f.write(f\"a = {a_final.tolist()}\\n\")\n        f.write(f\"b = {b_final.tolist()}\\n\")\n        f.write(f\"coef = {coef_final}\\n\")\n        f.write(f\"shift = {shift_final}\\n\")\n        \n        f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n        f.write(\"Mathematica format:\\n\")\n        a_str = \", \".join([f\"{x:.17g}\" for x in a_final])\n        b_str = \", \".join([f\"{x:.17g}\" for x in b_final])\n        f.write(f\"a = {{{a_str}}};\\n\")\n        f.write(f\"b = {{{b_str}}};\\n\")\n        f.write(f\"coef = {coef_final:.17g};\\n\")\n        f.write(f\"shift = {shift_final:.17g};\\n\")\n    \n    if verbose:\n        print(f\"  Saved to {results_dir}/T{temp}_*\")\n    \n    return {\n        'temp': temp,\n        'filename': filename,\n        'a': a_final,\n        'b': b_final,\n        'coef': coef_final,\n        'shift': shift_final,\n        'obj_final': obj_final,\n        'total_loss': comp_final['total_loss'],\n        'data_fit_error': comp_final['data_fit_error'],\n        'nec_penalty': comp_final['nec_penalty'],\n        'nec_violation': comp_final['nec_violation'],\n        'Lmax_model': comp_final['Lmax_model'],\n        'chi2_data': comp_final['chi2_data'],\n        'success': result.success,\n        'nfev': result.nfev\n    }"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Batch Optimization for All Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================================================================\n",
      "STARTING BATCH OPTIMIZATION FOR 9 TEMPERATURES\n",
      "======================================================================\n",
      "\n",
      "\n",
      "######################################################################\n",
      "# TEMPERATURE 1/9: T = 113 MeV\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "OPTIMIZING T = 113 MeV\n",
      "File: 1607latticeT113.txt\n",
      "======================================================================\n",
      "  Dataset: 28 points\n",
      "  L range: [0.0513, 0.7682]\n",
      "\n",
      "  *** ERROR for T=113: a leaf Variable that requires grad is being used in an in-place operation.\n",
      "  *** Skipping this temperature and continuing...\n",
      "\n",
      "\n",
      "######################################################################\n",
      "# TEMPERATURE 2/9: T = 226 MeV\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "OPTIMIZING T = 226 MeV\n",
      "File: 1607latticeT226.txt\n",
      "======================================================================\n",
      "  Dataset: 25 points\n",
      "  L range: [0.1025, 1.3444]\n",
      "\n",
      "  *** ERROR for T=226: a leaf Variable that requires grad is being used in an in-place operation.\n",
      "  *** Skipping this temperature and continuing...\n",
      "\n",
      "\n",
      "######################################################################\n",
      "# TEMPERATURE 3/9: T = 254 MeV\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "OPTIMIZING T = 254 MeV\n",
      "File: 1607latticeT254.txt\n",
      "======================================================================\n",
      "  Dataset: 22 points\n",
      "  L range: [0.1153, 1.3722]\n",
      "\n",
      "  *** ERROR for T=254: a leaf Variable that requires grad is being used in an in-place operation.\n",
      "  *** Skipping this temperature and continuing...\n",
      "\n",
      "\n",
      "######################################################################\n",
      "# TEMPERATURE 4/9: T = 271 MeV\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "OPTIMIZING T = 271 MeV\n",
      "File: 1607latticeT271.txt\n",
      "======================================================================\n",
      "  Dataset: 21 points\n",
      "  L range: [0.1230, 1.3828]\n",
      "\n",
      "  *** ERROR for T=271: a leaf Variable that requires grad is being used in an in-place operation.\n",
      "  *** Skipping this temperature and continuing...\n",
      "\n",
      "\n",
      "######################################################################\n",
      "# TEMPERATURE 5/9: T = 290 MeV\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "OPTIMIZING T = 290 MeV\n",
      "File: 1607latticeT290.txt\n",
      "======================================================================\n",
      "  Dataset: 18 points\n",
      "  L range: [0.1318, 1.2831]\n",
      "\n",
      "  *** ERROR for T=290: a leaf Variable that requires grad is being used in an in-place operation.\n",
      "  *** Skipping this temperature and continuing...\n",
      "\n",
      "\n",
      "######################################################################\n",
      "# TEMPERATURE 6/9: T = 312 MeV\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "OPTIMIZING T = 312 MeV\n",
      "File: 1607latticeT312.txt\n",
      "======================================================================\n",
      "  Dataset: 18 points\n",
      "  L range: [0.1420, 1.3818]\n",
      "\n",
      "  *** ERROR for T=312: a leaf Variable that requires grad is being used in an in-place operation.\n",
      "  *** Skipping this temperature and continuing...\n",
      "\n",
      "\n",
      "######################################################################\n",
      "# TEMPERATURE 7/9: T = 338 MeV\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "OPTIMIZING T = 338 MeV\n",
      "File: 1607latticeT338.txt\n",
      "======================================================================\n",
      "  Dataset: 15 points\n",
      "  L range: [0.1538, 1.3306]\n",
      "\n",
      "  *** ERROR for T=338: a leaf Variable that requires grad is being used in an in-place operation.\n",
      "  *** Skipping this temperature and continuing...\n",
      "\n",
      "\n",
      "######################################################################\n",
      "# TEMPERATURE 8/9: T = 369 MeV\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "OPTIMIZING T = 369 MeV\n",
      "File: 1607latticeT369.txt\n",
      "======================================================================\n",
      "  Dataset: 14 points\n",
      "  L range: [0.1678, 1.2701]\n",
      "\n",
      "  *** ERROR for T=369: a leaf Variable that requires grad is being used in an in-place operation.\n",
      "  *** Skipping this temperature and continuing...\n",
      "\n",
      "\n",
      "######################################################################\n",
      "# TEMPERATURE 9/9: T = 406 MeV\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "OPTIMIZING T = 406 MeV\n",
      "File: 1607latticeT406.txt\n",
      "======================================================================\n",
      "  Dataset: 14 points\n",
      "  L range: [0.1845, 1.3971]\n",
      "\n",
      "  *** ERROR for T=406: a leaf Variable that requires grad is being used in an in-place operation.\n",
      "  *** Skipping this temperature and continuing...\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "BATCH OPTIMIZATION COMPLETE\n",
      "Successfully optimized 0/9 temperatures\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/1964647463.py\", line 14, in <module>\n",
      "    result = optimize_params_all_temperatures(filename, temp, verbose=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/3076048715.py\", line 35, in optimize_params_all_temperatures\n",
      "    model.a.zero_()\n",
      "RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/1964647463.py\", line 14, in <module>\n",
      "    result = optimize_params_all_temperatures(filename, temp, verbose=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/3076048715.py\", line 35, in optimize_params_all_temperatures\n",
      "    model.a.zero_()\n",
      "RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/1964647463.py\", line 14, in <module>\n",
      "    result = optimize_params_all_temperatures(filename, temp, verbose=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/3076048715.py\", line 35, in optimize_params_all_temperatures\n",
      "    model.a.zero_()\n",
      "RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/1964647463.py\", line 14, in <module>\n",
      "    result = optimize_params_all_temperatures(filename, temp, verbose=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/3076048715.py\", line 35, in optimize_params_all_temperatures\n",
      "    model.a.zero_()\n",
      "RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/1964647463.py\", line 14, in <module>\n",
      "    result = optimize_params_all_temperatures(filename, temp, verbose=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/3076048715.py\", line 35, in optimize_params_all_temperatures\n",
      "    model.a.zero_()\n",
      "RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/1964647463.py\", line 14, in <module>\n",
      "    result = optimize_params_all_temperatures(filename, temp, verbose=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/3076048715.py\", line 35, in optimize_params_all_temperatures\n",
      "    model.a.zero_()\n",
      "RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/1964647463.py\", line 14, in <module>\n",
      "    result = optimize_params_all_temperatures(filename, temp, verbose=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/3076048715.py\", line 35, in optimize_params_all_temperatures\n",
      "    model.a.zero_()\n",
      "RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/1964647463.py\", line 14, in <module>\n",
      "    result = optimize_params_all_temperatures(filename, temp, verbose=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/3076048715.py\", line 35, in optimize_params_all_temperatures\n",
      "    model.a.zero_()\n",
      "RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/1964647463.py\", line 14, in <module>\n",
      "    result = optimize_params_all_temperatures(filename, temp, verbose=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hq/yn5dxnvn1vqgp11804klfycw0000gp/T/ipykernel_12591/3076048715.py\", line 35, in optimize_params_all_temperatures\n",
      "    model.a.zero_()\n",
      "RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.\n"
     ]
    }
   ],
   "source": [
    "# Run optimization for all temperatures\n",
    "all_results = []\n",
    "\n",
    "print(f\"\\n\\n{'='*70}\")\n",
    "print(f\"STARTING BATCH OPTIMIZATION FOR {len(temp_files)} TEMPERATURES\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "for idx, (temp, filename) in enumerate(temp_files, 1):\n",
    "    print(f\"\\n{'#'*70}\")\n",
    "    print(f\"# TEMPERATURE {idx}/{len(temp_files)}: T = {temp} MeV\")\n",
    "    print(f\"{'#'*70}\")\n",
    "    \n",
    "    try:\n",
    "        result = optimize_params_all_temperatures(filename, temp, verbose=True)\n",
    "        all_results.append(result)\n",
    "        \n",
    "        # Print summary for this temperature\n",
    "        print(f\"\\n  RESULTS FOR T = {temp} MeV:\")\n",
    "        print(f\"    a = [{result['a'][0]:.4f}, {result['a'][1]:.4f}, {result['a'][2]:.4f}, {result['a'][3]:.4f}]\")\n",
    "        print(f\"    b = [{result['b'][0]:.4f}, {result['b'][1]:.4f}, {result['b'][2]:.4f}, {result['b'][3]:.4f}]\")\n",
    "        print(f\"    coef = {result['coef']:.6f}, shift = {result['shift']:.4f}\")\n",
    "        print(f\"    Swallowtail L_max = {result['Lmax_model']:.4f}\")\n",
    "        print(f\"    Chi2 = {result['chi2_data']:.4e}\")\n",
    "        print(f\"    Success: {result['success']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n  *** ERROR for T={temp}: {e}\")\n",
    "        print(f\"  *** Skipping this temperature and continuing...\\n\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "print(f\"\\n\\n{'='*70}\")\n",
    "print(f\"BATCH OPTIMIZATION COMPLETE\")\n",
    "print(f\"Successfully optimized {len(all_results)}/{len(temp_files)} temperatures\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary table\n",
    "summary_file = results_dir / 'all_temperatures_summary.txt'\n",
    "\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(\"=\"*100 + \"\\n\")\n",
    "    f.write(\"SUMMARY: ALL TEMPERATURES\\n\")\n",
    "    f.write(\"=\"*100 + \"\\n\\n\")\n",
    "    \n",
    "    # Header\n",
    "    f.write(f\"{'T[MeV]':>7} {'a[0]':>12} {'a[1]':>12} {'a[2]':>12} {'a[3]':>12} \")\n",
    "    f.write(f\"{'b[1]':>12} {'b[2]':>12} {'b[3]':>12} {'coef':>10} {'shift':>10} \")\n",
    "    f.write(f\"{'L_max':>8} {'chi2':>10} {'Success':>7}\\n\")\n",
    "    f.write(\"-\"*100 + \"\\n\")\n",
    "    \n",
    "    for r in all_results:\n",
    "        f.write(f\"{r['temp']:7d} \")\n",
    "        f.write(f\"{r['a'][0]:12.6f} {r['a'][1]:12.6f} {r['a'][2]:12.6f} {r['a'][3]:12.6f} \")\n",
    "        f.write(f\"{r['b'][1]:12.6f} {r['b'][2]:12.6f} {r['b'][3]:12.6f} \")\n",
    "        f.write(f\"{r['coef']:10.6f} {r['shift']:10.4f} \")\n",
    "        f.write(f\"{r['Lmax_model']:8.4f} {r['chi2_data']:10.2e} \")\n",
    "        f.write(f\"{'Yes' if r['success'] else 'No':>7}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\"*100 + \"\\n\")\n",
    "    f.write(f\"Total: {len(all_results)} temperatures\\n\")\n",
    "    f.write(f\"Results saved to: {results_dir.absolute()}\\n\")\n",
    "    f.write(\"=\"*100 + \"\\n\")\n",
    "\n",
    "print(f\"\\nSummary table saved to: {summary_file}\")\n",
    "print(f\"\\nAll results saved to: {results_dir.absolute()}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Display Summary Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Display Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_temperatures_combined(all_results):\n",
    "    \"\"\"\n",
    "    Plot all temperatures together with color gradient from cold to warm.\n",
    "    \"\"\"\n",
    "    n_temps = len(all_results)\n",
    "    if n_temps == 0:\n",
    "        print(\"No results to plot!\")\n",
    "        return\n",
    "    \n",
    "    # Create color map from cold (blue) to warm (red)\n",
    "    colors = plt.cm.coolwarm(np.linspace(0.0, 1.0, n_temps))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    print(f\"\\nPlotting {n_temps} temperatures together...\")\n",
    "    \n",
    "    for idx, result in enumerate(all_results):\n",
    "        temp = result['temp']\n",
    "        filename = result['filename']\n",
    "        color = colors[idx]\n",
    "        \n",
    "        # Load data\n",
    "        dataset = AdSBHDataset(file=filename)\n",
    "        mask_L = dataset.L < 1.4\n",
    "        L_data = dataset.L[mask_L]\n",
    "        V_data = dataset.V[mask_L]\n",
    "        sigma_data = dataset.sigma[mask_L]\n",
    "        \n",
    "        # Setup model with optimized parameters\n",
    "        model = AdSBHNet(N=N_COEFFS, std=0.1)\n",
    "        device = model.a.device\n",
    "        dt = model.a.dtype\n",
    "        \n",
    "        # Set optimized parameters\n",
    "        model.a.copy_(torch.tensor(result['a'], dtype=dt, device=device))\n",
    "        model.b.copy_(torch.tensor(result['b'], dtype=dt, device=device))\n",
    "        model.logcoef.copy_(torch.tensor(np.log(result['coef']), dtype=dt, device=device))\n",
    "        model.shift.copy_(torch.tensor(result['shift'], dtype=dt, device=device))\n",
    "        \n",
    "        # Compute optimized curve\n",
    "        with torch.no_grad():\n",
    "            Lm, Vm = connected_branch(model, device, dt, Nc=5000)\n",
    "            V_branch = (Vm + model.shift).cpu()\n",
    "            Lm = Lm.cpu()\n",
    "        \n",
    "        # Plot data points (with error bars)\n",
    "        ax.errorbar(L_data.cpu(), V_data.real.cpu(), yerr=sigma_data.real.cpu(),\n",
    "                    fmt='o', markersize=5, alpha=0.6, color=color, \n",
    "                    label=f'T={temp} MeV (data)', zorder=1)\n",
    "        \n",
    "        # Plot optimized curve\n",
    "        ax.plot(Lm, V_branch, '-', linewidth=2.5, color=color, alpha=0.9, zorder=2)\n",
    "    \n",
    "    ax.set_xlabel(r'$T L$', fontsize=14)\n",
    "    ax.set_ylabel(r'$V/T$ (real part)', fontsize=14)\n",
    "    ax.set_title(f'All Temperatures: Data and Optimized Models\\\\n(Cold to Warm: T = {all_results[0][\\\"temp\\\"]} → {all_results[-1][\\\"temp\\\"]} MeV)', \n",
    "                 fontsize=15)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # Create custom legend\n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor='gray', \n",
    "               markersize=8, label='Data points'),\n",
    "        Line2D([0], [0], color='gray', linewidth=2.5, label='Optimized curves')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, fontsize=12, loc='best')\n",
    "    \n",
    "    # Add colorbar to show temperature gradient\n",
    "    sm = plt.cm.ScalarMappable(cmap=plt.cm.coolwarm, \n",
    "                                norm=plt.Normalize(vmin=all_results[0]['temp'], \n",
    "                                                   vmax=all_results[-1]['temp']))\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, label='Temperature (MeV)', pad=0.02)\n",
    "    cbar.ax.tick_params(labelsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    output_file = results_dir / 'all_temperatures_combined.png'\n",
    "    plt.savefig(output_file, dpi=200, bbox_inches='tight')\n",
    "    print(f\"Saved combined plot to: {output_file}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "# Create the combined plot\n",
    "fig, ax = plot_all_temperatures_combined(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Combined Plot: All Temperatures Together\n",
    "\n",
    "Plot all temperature data and optimized curves in one figure, color-coded from cold (blue) to hot (red)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\"*100)\n",
    "print(f\"{'T[MeV]':>7} {'a[0]':>12} {'a[1]':>12} {'a[2]':>12} {'a[3]':>12} \", end=\"\")\n",
    "print(f\"{'b[1]':>12} {'b[2]':>12} {'b[3]':>12} {'coef':>10} {'shift':>10} \", end=\"\")\n",
    "print(f\"{'L_max':>8} {'chi2':>10} {'Success':>7}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for r in all_results:\n",
    "    print(f\"{r['temp']:7d} \", end=\"\")\n",
    "    print(f\"{r['a'][0]:12.6f} {r['a'][1]:12.6f} {r['a'][2]:12.6f} {r['a'][3]:12.6f} \", end=\"\")\n",
    "    print(f\"{r['b'][1]:12.6f} {r['b'][2]:12.6f} {r['b'][3]:12.6f} \", end=\"\")\n",
    "    print(f\"{r['coef']:10.6f} {r['shift']:10.4f} \", end=\"\")\n",
    "    print(f\"{r['Lmax_model']:8.4f} {r['chi2_data']:10.2e} \", end=\"\")\n",
    "    print(f\"{'Yes' if r['success'] else 'No':>7}\")\n",
    "\n",
    "print(\"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}